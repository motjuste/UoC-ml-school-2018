{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-compute Embeddings from `vggish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- All data has been split into `train`, `val` and `test` sets.\n",
    "- All audio data have corresponding labels with the same filename (except extension).\n",
    "- Running `audioset/vggish_smoke_test.py` is successful.\n",
    "- Running `pytest tests` from inside `rennet` is successful (ignore warnings for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.283420Z",
     "start_time": "2018-09-27T15:04:48.990045Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "import feat_ext as fx\n",
    "from audioset import vggish_slim\n",
    "from rennet.datasets.ka3 import ActiveSpeakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.296392Z",
     "start_time": "2018-09-27T15:04:59.285444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Where to look?\n",
    "\n",
    "dir_splits_root = Path.cwd().joinpath(\"data/working/ka3/fx/splits_20180927\")\n",
    "\n",
    "if not dir_splits_root.exists():\n",
    "    raise RuntimeError(f\"splits_root does not exist at: {dir_splits_root}\")\n",
    "    \n",
    "print(f'splits_root:\\n{dir_splits_root}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.314400Z",
     "start_time": "2018-09-27T15:04:59.299392Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_trn = dir_splits_root.joinpath('trn')\n",
    "dir_val = dir_splits_root.joinpath('val')\n",
    "dir_tst = dir_splits_root.joinpath('tst')\n",
    "\n",
    "for split in [dir_trn, dir_val, dir_tst]:\n",
    "    if not split.exists():\n",
    "        raise RuntimeError(f'split directory does not exist: {split}')\n",
    "        \n",
    "print('splits:', dir_trn, dir_val, dir_tst, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.501400Z",
     "start_time": "2018-09-27T15:04:59.317393Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ActiveSpeakers_labels(filepath):\n",
    "    return ActiveSpeakers.from_file(\n",
    "        filepath, \n",
    "        use_tags='ns', \n",
    "        tiers=lambda tn: \"x@\" in tn or tn.startswith(\"sp\"), \n",
    "        warn_duplicates=False\n",
    "    )\n",
    "\n",
    "pairs_trn = fx.AudioLabelPair.all_in_dir(dir_trn, \"*.wav\", \"*.eaf\", labels_parser=get_ActiveSpeakers_labels)\n",
    "pairs_val = fx.AudioLabelPair.all_in_dir(dir_val, \"*.wav\", \"*.eaf\", labels_parser=get_ActiveSpeakers_labels)\n",
    "pairs_tst = fx.AudioLabelPair.all_in_dir(dir_tst, \"*.wav\", \"*.eaf\", labels_parser=get_ActiveSpeakers_labels)\n",
    "\n",
    "print(f'trn audio-label-pairs: {len(pairs_trn)}\\t{sum(p.audio.seconds for p in pairs_trn):.2f}sec')\n",
    "print(f'val audio-label-pairs: {len(pairs_val)}\\t{sum(p.audio.seconds for p in pairs_val):.2f}sec')\n",
    "print(f'tst audio-label-pairs: {len(pairs_tst)}\\t{sum(p.audio.seconds for p in pairs_tst):.2f}sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.517394Z",
     "start_time": "2018-09-27T15:04:59.503407Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_trn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Output Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.533397Z",
     "start_time": "2018-09-27T15:04:59.520397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Where to output\n",
    "\n",
    "dir_pickles_root = dir_splits_root.joinpath(\"pickles\")\n",
    "\n",
    "dir_this_pickles = dir_pickles_root.joinpath(\"20180927-vggish_embedding\")\n",
    "dir_this_pickles.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f'pickles for each split will be saved at:\\n{dir_this_pickles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Pickles (`tfrecord`) for each split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGGish model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.549395Z",
     "start_time": "2018-09-27T15:04:59.536392Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_vggish = Path.cwd().joinpath('data/models/vggish')\n",
    "fp_vggish_model = dir_vggish.joinpath('vggish_model.ckpt')\n",
    "fp_vggish_pca_params = dir_vggish.joinpath('vggish_pca_params.npz')\n",
    "\n",
    "for fp in [fp_vggish_model, fp_vggish_pca_params]:\n",
    "    if not fp.exists():\n",
    "        raise RuntimeError(\"model file {fp} not found.\")\n",
    "        \n",
    "print(f'vggish_model:\\n{fp_vggish_model}\\n')\n",
    "print(f'vggish_pca_params:\\n{fp_vggish_pca_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.566425Z",
     "start_time": "2018-09-27T15:04:59.554399Z"
    }
   },
   "outputs": [],
   "source": [
    "p = pairs_trn[0]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:04:59.584392Z",
     "start_time": "2018-09-27T15:04:59.569394Z"
    }
   },
   "outputs": [],
   "source": [
    "post_processor = fx.get_pre_processor(fp_vggish_pca_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T15:14:01.572857Z",
     "start_time": "2018-09-27T15:04:59.589392Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, str(fp_vggish_model.absolute()))\n",
    "    \n",
    "    for (name, pairs) in [\n",
    "            ('val', pairs_val), \n",
    "            ('tst', pairs_tst), \n",
    "            ('trn', pairs_trn)\n",
    "        ]:\n",
    "        with tf.python_io.TFRecordWriter(str(dir_this_pickles.joinpath(f'{name}.tfrecord'))) as writer:\n",
    "            for (i, pair) in enumerate(pairs):\n",
    "                print(f'Processing {name} ... {100*(i)/len(pairs):5.2f}%', end='\\r', flush=True)\n",
    "                try:\n",
    "                    ex = pair.to_vggish_SequenceExample(sess, post_processor)\n",
    "                    writer.write(ex.SerializeToString())\n",
    "                except:\n",
    "                    print(pair.audio)\n",
    "                    print(pair._get_audio_examples().shape)\n",
    "                    print(pair._get_label_examples().shape)\n",
    "                \n",
    "        print(f'Processing {name} ... {100*(i+1)/len(pairs):5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-school]",
   "language": "python",
   "name": "conda-env-ml-school-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
